= scdf-raven

== Prepare Env

. Download PCFDev, a full, local install of Cloudfoundry

. Extract PCFDev zip archive

. Start PCFDev using Vagrant start scripts (start-osx or start-windows)

. Log into PCFDev using CF CLI
+
[source,bash]
---------------------------------------------------------------------
$ cf login -a api.local.pcfdev.io --skip-ssl-validation -u admin -p admin
---------------------------------------------------------------------

. Create the required RabbitMQ and Redis service instances
+
[source,bash]
---------------------------------------------------------------------
$ cf create-service p-rabbitmq standard rabbit
$ cf create-service p-redis shared-vm redis
---------------------------------------------------------------------

== Deploy Spring Cloud Dataflow Server

. Change directories to the _df-server_ directory

. Deploy the Spring Cloud Dataflow server to Cloudfoundry
+
[source,bash]
---------------------------------------------------------------------
$ cf push
---------------------------------------------------------------------

. After the application starts up you will have dataflow running.  If you'd like, you cann access the Dataflow UI here: http://dataflow-server.local.pcfdev.io/admin-ui/

. By Default you will not have any Stream applications (modules) available.  We'll use the Spring Cloud Dataflow shell to load them.

. Change directories to the _df-shell_ directory and execute the dataflow shell command, _dataflow config server_, to configure our server backend:
+
[source,bash]
---------------------------------------------------------------------
$ mvn clean spring-boot:run
---------------------------------------------------------------------

. After the Shell loads we need to target our deployed dataflow server:
+
[source,bash]
---------------------------------------------------------------------
  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/

1.0.0.M3

Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".


server-unknown:> dataflow config server http://dataflow-server.local.pcfdev.io
Successfully targeted http://dataflow-server.local.pcfdev.io

---------------------------------------------------------------------

.  Your shell should now be targeted correctly.  Test this by listing the current streams (which shoul dbe empty right now):
+
[source,bash]
---------------------------------------------------------------------
dataflow:>stream list
╔═══════════╤═════════════════╤══════╗
║Stream Name│Stream Definition│Status║
╚═══════════╧═════════════════╧══════╝

---------------------------------------------------------------------

. Load the Spring Cloud Dataflow modules by executing this command.  Be sure to replace $LOCAL_FILESYSTEM_PATH with your correct system path to this git project:
+
[source,bash]
---------------------------------------------------------------------
dataflow:>module import --uri file://$LOCAL_FILESYSTEM_PATH/df-shell/module.properties --local TRUE

Successfully registered modules: [source.tcp, task.timestamp, source.http, sink.jdbc, sink.rabbit, source.rabbit, source.ftp, sink.gpfdist, processor.transform, source.sftp, processor.filter, source.file, sink.cassandra, processor.groovy-filter, sink.router, source.trigger, processor.splitter, sink.redis, source.load-generator, sink.file, source.time, source.twitterstream, sink.tcp, source.jdbc, sink.field-value-counter, sink.hdfs, processor.bridge, processor.pmml, processor.httpclient, sink.ftp, sink.log, sink.gemfire, sink.aggregate-counter, sink.throughput, source.jms, processor.scriptable-transform, sink.counter, sink.websocket, processor.groovy-transform]

---------------------------------------------------------------------

. List the loaded modules using the shell:
+
[source,bash]
---------------------------------------------------------------------
dataflow:>module list
╔══════════════╤════════════════════╤═══════════════════╤═════════╗
║    source    │     processor      │       sink        │  task   ║
╠══════════════╪════════════════════╪═══════════════════╪═════════╣
║file          │bridge              │aggregate-counter  │timestamp║
║ftp           │filter              │cassandra          │         ║
║http          │groovy-filter       │counter            │         ║
║jdbc          │groovy-transform    │field-value-counter│         ║
║jms           │httpclient          │file               │         ║
║load-generator│pmml                │ftp                │         ║
║rabbit        │scriptable-transform│gemfire            │         ║
║sftp          │splitter            │gpfdist            │         ║
║tcp           │transform           │hdfs               │         ║
║time          │                    │jdbc               │         ║
║trigger       │                    │log                │         ║
║twitterstream │                    │rabbit             │         ║
║              │                    │redis              │         ║
║              │                    │router             │         ║
║              │                    │tcp                │         ║
║              │                    │throughput         │         ║
║              │                    │websocket          │         ║
╚══════════════╧════════════════════╧═══════════════════╧═════════╝

---------------------------------------------------------------------

== Load Custom Modules and Create a Stream using the Spring Cloud Dataflow Shell

.Test